{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plant_identification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXCQJ29_yb9x"
      },
      "source": [
        "### <b>식물 이미지 분류 학습</b>\n",
        "\n",
        "* 순서\n",
        "    1. 이미지 크롤링(image crawling) 혹은 크롤링 라이브러리\n",
        "    2. 전이 학습(transfer learning)\n",
        "    3. 웹 API 개발\n",
        "* <b>식물</b> 분류기(classifier)\n",
        "* 과정\n",
        "    * 데이터 수집/정제\n",
        "    * 인공지능 모델 학습\n",
        "    * 학습된 모델 배포\n",
        "* 한글 폰트 설치 이후에 <b>[런타임] - [런타임 다시 시작]</b>을 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km0yMQoGgGRc"
      },
      "source": [
        "# 한글 폰트 설치하기 (꼭! 설치가 완료되면 [런타임 다시 시작]을 누르고 다시 실행하기)\n",
        "!apt install fonts-nanum -y\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 한글 폰트 설정하기\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=10)\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "matplotlib.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj6p24YpIl07"
      },
      "source": [
        "# 필요한 라이브러리 설치하기\n",
        "!git clone https://github.com/ndb796/bing_image_downloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCwH2ajVzDHM"
      },
      "source": [
        "#### <b>1. 이미지 크롤링을 활용한 학습 이미지 수집</b>\n",
        "\n",
        "* 수집한 이미지를 저장하기 위한 폴더를 생성하고, 필요한 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3az4in0AR5R"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from bing_image_downloader.bing_image_downloader import downloader\n",
        "\n",
        "\n",
        "directory_list = [\n",
        "    './custom_dataset/train/',\n",
        "    './custom_dataset/test/',\n",
        "]\n",
        "\n",
        "# 초기 디렉토리 만들기\n",
        "for directory in directory_list:\n",
        "    if not os.path.isdir(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# 수집한 이미지를 학습 데이터와 평가 데이터로 구분하는 함수\n",
        "def dataset_split(query, train_cnt):\n",
        "    # 학습 및 평가 데이터셋 디렉토리 만들기\n",
        "    for directory in directory_list:\n",
        "        if not os.path.isdir(directory + '/' + query):\n",
        "            os.makedirs(directory + '/' + query)\n",
        "    # 학습 및 평가 데이터셋 준비하기\n",
        "    cnt = 0\n",
        "    for file_name in os.listdir(query):\n",
        "        if cnt < train_cnt:\n",
        "            print(f'[Train Dataset] {file_name}')\n",
        "            shutil.move(query + '/' + file_name, './custom_dataset/train/' + query + '/' + file_name)\n",
        "        else:\n",
        "            print(f'[Test Dataset] {file_name}')\n",
        "            shutil.move(query + '/' + file_name, './custom_dataset/test/' + query + '/' + file_name)\n",
        "        cnt += 1\n",
        "    shutil.rmtree(query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYz-8H4JY66i"
      },
      "source": [
        "* <b>장미</b> 이미지 크롤링을 진행하고 데이터셋을 구축합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm1ucFykGhwk"
      },
      "source": [
        "query = '장미'\n",
        "downloader.download(query, limit=40,  output_dir='./', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "dataset_split(query, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2fQOykH41eG"
      },
      "source": [
        "#### <b>2. PyTorch를 이용한 전이 학습(Transfer Learning)</b>\n",
        "\n",
        "* 학습을 위해 필요한 라이브러리를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb_-upl6A0JG"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xFhGpZiBaJo"
      },
      "source": [
        "* 데이터셋을 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O85lpUoA0rZ"
      },
      "source": [
        "# 데이터셋을 불러올 때 사용할 변형(transformation) 객체 정의\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(), # 데이터 증진(augmentation)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "data_dir = './custom_dataset'\n",
        "train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms_train)\n",
        "test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'test'), transforms_test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=4)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=4, shuffle=True, num_workers=4)\n",
        "\n",
        "print('학습 데이터셋 크기:', len(train_datasets))\n",
        "print('테스트 데이터셋 크기:', len(test_datasets))\n",
        "\n",
        "class_names = train_datasets.classes\n",
        "print('클래스:', class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHmitYs3BfCf"
      },
      "source": [
        "* 간단히 이미지를 시각화해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlAApVf9A3Q3"
      },
      "source": [
        "def imshow(input, title):\n",
        "    # torch.Tensor를 numpy 객체로 변환\n",
        "    input = input.numpy().transpose((1, 2, 0))\n",
        "    # 이미지 정규화 해제하기\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    input = std * input + mean\n",
        "    input = np.clip(input, 0, 1)\n",
        "    # 이미지 출력\n",
        "    plt.imshow(input)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 학습 데이터를 배치 단위로 불러오기\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "# 현재 배치를 이용해 격자 형태의 이미지를 만들어 시각화\n",
        "inputs, classes = next(iterator)\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfX1atx-Bh2l"
      },
      "source": [
        "* 학습할 CNN 딥러닝 모델 객체를 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jjW3KQvA8S_"
      },
      "source": [
        "model = models.resnet34(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "# 전이 학습(transfer learning): 모델의 출력 뉴런 수를 3개로 교체하여 마지막 레이어 다시 학습\n",
        "model.fc = nn.Linear(num_features, 3)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c06wJhJ9BmWV"
      },
      "source": [
        "* 학습을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY-5hWhJA-_0"
      },
      "source": [
        "num_epochs = 50\n",
        "model.train()\n",
        "start_time = time.time()\n",
        "\n",
        "# 전체 반복(epoch) 수 만큼 반복하며\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.\n",
        "    running_corrects = 0\n",
        "\n",
        "    # 배치 단위로 학습 데이터 불러오기\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 모델에 입력(forward)하고 결과 계산\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_datasets)\n",
        "    epoch_acc = running_corrects / len(train_datasets) * 100.\n",
        "\n",
        "    # 학습 과정 중에 결과 출력\n",
        "    print('#{} Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLM2YvrPLaRj"
      },
      "source": [
        "* 학습된 모델을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POugVbTQBBeg"
      },
      "source": [
        "model.eval()\n",
        "start_time = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    running_loss = 0.\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in test_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # 한 배치의 첫 번째 이미지에 대하여 결과 시각화\n",
        "        print(f'[예측 결과: {class_names[preds[0]]}] (실제 정답: {class_names[labels.data[0]]})')\n",
        "        imshow(inputs.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n",
        "\n",
        "    epoch_loss = running_loss / len(test_datasets)\n",
        "    epoch_acc = running_corrects / len(test_datasets) * 100.\n",
        "    print('[Test Phase] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch_loss, epoch_acc, time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "105aRPchgxUl"
      },
      "source": [
        "#### <b>3. 분류 모델 API 개발</b>\n",
        "\n",
        "* 학습된 분류 모델을 다른 사람이 사용할 수 있도록 API를 개발하여 배포합니다.\n",
        "* 먼저 한 장의 이미지를 파일로부터 읽어와 분류 결과를 반환하는 기능을 작성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIA4wgsbf3GY"
      },
      "source": [
        "# 테스트용 이미지 다운로드하기\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/f/f1/Don_Lee_by_Gage_Skidmore.jpg -O test_image.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os4YudlBY47G"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "image = Image.open('test_image.jpg')\n",
        "image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(image)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    imshow(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzbLpVgWixqu"
      },
      "source": [
        "* 웹 API 개방을 위해 <b>Ngrok</b> 서비스를 이용합니다.\n",
        "* API 기능 제공을 위해 <b>Flask 프레임워크</b>를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLFqO9cpSmFj"
      },
      "source": [
        "# 필요한 라이브러리 설치하기\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlqhcM1ZXcro"
      },
      "source": [
        "import io\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, jsonify, request\n",
        "\n",
        "\n",
        "# 이미지를 읽어 결과를 반환하는 함수\n",
        "def get_prediction(image_bytes):\n",
        "    image = Image.open(io.BytesIO(image_bytes))\n",
        "    image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        imshow(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n",
        "\n",
        "    return class_names[preds[0]]\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def predict():\n",
        "    if request.method == 'POST':\n",
        "        # 이미지 바이트 데이터 받아오기\n",
        "        file = request.files['file']\n",
        "        image_bytes = file.read()\n",
        "\n",
        "        # 분류 결과 확인 및 클라이언트에게 결과 반환\n",
        "        class_name = get_prediction(image_bytes=image_bytes)\n",
        "        print(\"결과:\", {'class_name': class_name})\n",
        "        return jsonify({'class_name': class_name})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK1R-B4HpL76"
      },
      "source": [
        "* API를 개방할 수 있으며 실행할 때마다 서버의 주소가 변경됩니다.\n",
        "* 서버 주소를 정확히 확인할 필요가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzrf6fbDaARx"
      },
      "source": [
        "run_with_ngrok(app)\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HcDhd8SjwSj"
      },
      "source": [
        "* 클라이언트 테스트 방법\n",
        "\n",
        "<pre>\n",
        "curl -X POST -F file=@{이미지 파일명} {Ngrok 서버 주소}\n",
        "</pre>\n",
        "\n",
        "* 사용 예시\n",
        "\n",
        "<pre>\n",
        "curl -X POST -F file=@dongseok.jpg http://c4cdb8de3a35.ngrok.io/\n",
        "</pre>\n",
        "\n",
        "* 이러한 방식으로 웹, 모바일, 게임 등의 소프트웨어 환경에서 API를 호출하는 방식으로 인공지능 앱을 개발할 수 있습니다."
      ]
    }
  ]
}